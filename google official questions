# Q. 
あなたは、単一のテーブルで繰り返し実行されるクエリについて、BigQuery の最適化に取り組んでいます。クエリされるデータは約 1 GB で、一部の行は 1 時間に約 10 回変更されることが予想されます。SQL ステートメントは可能な限りの最適化が済んでおり、クエリのパフォーマンスをさらに最適化したいと考えています。どうすればよいですか。
A. テーブルに基づくマテリアライズド ビューを作成して、そのビューをクエリします。
B. クエリデータのキャッシュ保存を有効にして、後続のクエリを高速化します。
C. スケジュール設定済みクエリを作成して、レポート作成の数分前にそのクエリを実行します。
D. 多数のスロットを事前に予約して、クエリの実行のためのコンピューティング能力を最大化します。

## A. A
マテリアライズド ビューは、パフォーマンスを向上させるためにクエリの結果を定期的にキャッシュ保存します。マテリアライズド ビューは、頻繁にクエリされる小さなデータセットに適しています。基盤となるテーブルデータが変更されると、影響を受ける部分をマテリアライズド ビューが無効化して再度読み込みます。
B: 選択肢 B は不正解です。キャッシュ保存は自動的に有効化されますが、基盤となるデータが変更されるとパフォーマンスを発揮できません。
C: 選択肢 C は不正解です。スケジュール設定済みクエリにより定期的なクエリをスケジュールできますが、パフォーマンスは特に最適化されません。また、クエリを早く実行しすぎると古いデータが使用される場合があります。
D: 選択肢 D は不正解です。多くのスロットを予約すると、BigQuery スロットの可用性は確保されますがパフォーマンスは向上しません。
ref: https://cloud.google.com/bigquery/docs/materialized-views-create?hl=ja

# Q. あなたの会社は、お客様に関するデータを収集してお客様の健康状態を定期的にチェックしています。お客様は世界中に数百万人います。データは、ユーザーあたり 10 秒ごとに 2 つのイベントという平均レートで取り込まれますが、データをユーザーごとに Bigtable で可視化できるようにする必要があります。オペレーションのパフォーマンスが高くなるように Bigtable キーを作成する必要がありますが、どうすればよいですか。
A. キーを user-id#device-id#activity-id#timestamp として作成します。
B. キーを timestamp#user-id#device-id#activity-id として作成します。
C. キーを timestamp#device-id#activity-id#user-id として作成します。
D. キーを user-id#timestamp#device-id#activity-id として作成します。

## A. D
Bigtable のパフォーマンスを最大限に引き出すには、行キーの設計が非常に重要です。キーは、書き込みがクラスター全体に均等に分散され（ホットスポッティングの回避）、かつ一般的な読み取りリクエストが効率的に行えるように設計する必要があります。
本問題における要件は2つ。
- 高い書き込みパフォーマンスの維持: 大量のデータを継続的に取り込むため、書き込みが特定のサーバーノードに集中する「ホットスポッティング」を避ける必要があります。→ user-idが先頭。
- ユーザーごとの効率的なデータ可視化: 特定のユーザーのデータを素早く読み取れる必要があります。→ この設計では、特定のユーザーのデータがすべて連続したブロックに格納されており、さらにタイムスタンプ順にソートされています。これにより、特定のユーザーの時系列データを非常に高速に取得できます。

# Q. あなたの会社は、BigQuery の知識がないビジネス アナリストを数人雇用していますが、今後、彼らは BigQuery を使用して大量のデータを分析する予定です。あなたは、BigQuery でのコスト管理を行い、クエリ結果の品質を維持しつつ予算が超過しないようにする必要があります。どうすればよいですか。
A. プロジェクト レベルまたはユーザーレベルでカスタマイズした 1 日の割り当てを許容できる値に設定します。
B. BigQuery テーブルのデータを減らしてアナリストがクエリするデータ量を減らしてから、残りのデータをアーカイブします。
C. クエリ検証ツールまたは --dry_run を使用して費用を見積もれるようにアナリストをトレーニングし、アナリストが使用量を自身で制御できるようにします。
D. 各アナリストに対し BigQuery の 1 日あたりの費用をエクスポートして Looker でデータを可視化し、アナリストが使用量を自身で制御できるようにします。

## A. A
予算超過を確実に防ぐためには、システム側で強制的な上限を設定する選択肢Aが最も適切。Bは使用する分析対象データ削除に該当するので不適切。Cは費用の管理がアナリスト依存で不適切。Dは事後対策になっているので不適切。

# Q. 最近、Bigtable データベースが本番環境にデプロイされ、取り込まれて分析されるデータ規模が大幅に増大しましたが、パフォーマンスが低下しました。パフォーマンスの問題を特定するにはどうすればよいですか。
A. Key Visualizer を使用してパフォーマンスを分析します。
B. Cloud Trace を使用してパフォーマンスの問題を特定します。
C. ログ ステートメントをコードに追加して、どの挿入が遅延の原因か調べます。
D. クラスタにノードをさらに追加して、パフォーマンスの問題が解消されるか確認します。

## A. A
Key Visualizer は、Bigtable のアクセスパターンを視覚的に分析するために設計された専用ツールです。
データ規模が大きくなったときに Bigtable のパフォーマンスが低下する最も一般的な原因は、ホットスポッティングです。これは、読み取りや書き込みがテーブル内の特定のキー範囲（つまり、特定のノード）に集中してしまう現象です。
Cloud Trace は、アプリケーション全体のリクエストの遅延を追跡するのに役立ちます。例えば、「API呼び出しの中で Bigtable への書き込みに時間がかかっている」ことは特定できますが、Bigtable の中でなぜ遅いのか（例：ホットスポットが原因なのか）までは分かりません。
Dは解決策の推測で、根本原因の特定のための作業ではないので不適切。

# Q. あなたの会社はデータ分析を BigQuery に移行しています。他のオペレーションはオンプレミスのままとなる予定です。このため、800 TB の過去のデータを転送する必要があります。また、翌日に分析するために、毎日 30 Gbps のデータ転送をアペンドする計画をしなくてはなりません。Google 推奨手法に従ってデータを転送するにはどうすればよいですか。
A. Cloud VPN を使用して、毎日できるだけ早く既存データをインターネットで転送します。
B. Transfer Appliance を使用して既存データを Google Cloud に移動します。Cloud VPN を使用して、データを毎日転送します。
C. Transfer Appliance を使用して既存データを Google Cloud に移動します。VPC ネットワーク ピアリングを使用して、データを毎日転送します。
D. Transfer Appliance を使用して既存データを Google Cloud に移動します。毎日の転送用に、Dedicated Interconnect または Partner Interconnect を設定します。

## A. D
このシナリオは、「大量の初期データ移行」と「高スループットの継続的なデータ転送」という2つの異なる要件を組み合わせたものです。Googleが推奨するアプローチは、それぞれの要件に最適なツールを使い分けることです。
Transfer Appliance: このような大規模なオフラインデータ転送のためにGoogleが提供しているのが Transfer Appliance です。これは、Googleから送られてくる物理的なストレージサーバーにオンプレミス環境でデータをコピーし、Googleに返送する方法です。データセンター側で直接クラウドにアップロードされるため、ネットワーク帯域幅に依存せず、迅速かつ安全にデータを移行できます。
Dedicated Interconnect または Partner Interconnect: これらは、オンプレミス環境とGoogleのネットワークをプライベートな専用線で接続する方法です。パブリックインターネットを経由しないため、安定した高速データ転送が可能です。さらに、プライベートな接続のため、セキュリティも向上します。
Cloud VPN: VPNはパブリックインターネットを経由するため、速度や安定性の保証がないため不適切。
VPC ネットワーク ピアリング: これはGoogle Cloud内のVPCネットワーク同士を接続するための技術であり、オンプレミス環境とGoogle Cloudを接続するものではないため不適切。

# Q. あなたのチームは Dataproc ワークロードを実行しており、ワーカーノードは処理に約 45 分かかります。費用の面から、ワーカーノードを積極的にシャットダウンすることも含めてシステムを最適化するさまざまな選択肢を検討してきましたが、指標ではジョブ全体がさらに長くなってしまいます。費用を抑えながらジョブ完了までの時間を延長せずにシステムを最適化するには、どうすればよいですか。
A. 正常なデコミッションのタイムアウトを 45 分より大きく設定します。
B. Cloud Data Fusion での処理を書き換えて、ジョブを自動で実行します。
C. Dataflow での処理を書き換えて、同一データのストリーム処理を使用します。
D. 各ワーカーノードの vCPU の数を増やして処理完了までの時間を短縮します。

## A. A
稼働中のサービスに対し、最適化されたオペレーションを設計している。シャットダウンフローもオペレーションの中に含むとして、費用を押さえて稼働中サービスの完了時間を引き延ばさない方法を問われている。
正常なデコミッション（Graceful Decommissioning）：ノード（特にプリエンプティブルVMやオートスケールで削減されるノード）をシャットダウンする際に、すぐには停止せず、現在実行中のタスクが完了するまで待機する仕組みです。これにより、計算途中の作業が無駄になるのを防ぎます。
Dataprocが持つこの機能により、コスト削減のためにワーカーノードを停止したいが、処理中のタスクが中断されてしまい、結果的にジョブ全体の時間が長くなってしまうというジレンマが解決されます。
B/Cは、多大な書き換えコストがかかる可能性があったり、アーキテクチャの根本的な変更になるため、問題の直接的な解決策にならず不適切。
Dは、ノードをより強力なもの（垂直スケーリング）にすると、処理時間は短くなるかもしれませんが、ノードあたりの単価が大幅に上がるため、総コストは増加する可能性が高いです。「費用を抑えながら」という要件に反します。 

# Q. お客様の SQL Server データベースには、別のパブリック クラウドにある約 5 TB のデータが含まれます。データは最大 25 TB まで増大することが予測されます。このデータベースは、週に 1 度使用される社内レポート アプリケーションのバックエンドです。このアプリケーションを Google Cloud に移行して、費用を同レベルに維持するか削減しつつ管理作業を軽減するには、どうすればよいですか。
A. データベースを Bigtable に移行します。
B. データベースを Cloud Spanner に移行します。
C. SQL Server を Compute Engine VM にインストールします。
D. データベースを Cloud SQL の SQL Server に移行します。

## A. D
BigtableはNoSQLデータベースです。リレーショナルデータベースであるSQL Serverから移行するには、スキーマの完全な再設計と、アプリケーションコードの大幅な書き換えが必要になり膨大な移行作業を発生させるため不適切。
Cloud Spannerは、金融取引など、高い可用性とグローバルなスケーラビリティが求められるミッションクリティカルなOLTP（オンライントランザクション処理）ワークロード向けに設計された、高性能・高コストのデータベースです。週に1度しか使われないレポートアプリケーションには過剰スペックであり、コスト要件を満たさないため不適切。
Cは、IaaS（Infrastructure as a Service）アプローチです。VM上に自前でSQL Serverを構築することになり、OSのパッチ適用、バックアップ、可用性の確保など、管理工数が増大するため不適切。
Dは、Cloud SQLは、Google Cloudが提供するフルマネージドのリレーショナルデータベースサービスです。バックアップ、パッチ適用、レプリケーション、フェイルオーバーといった面倒な運用タスクはすべてGoogleが自動で行ってくれます。移行元と同じSQL Serverエンジンを選択できるため、スキーマやアプリケーションの変更を最小限に抑えた「リフト＆シフト」が可能です。Cloud SQL for SQL Serverは最大64TBまでサポートしており、将来的に25TBまで増大するデータ量にも十分対応できます。

# Q. IT チームは構造化データの保存に BigQuery を使用しています。財務チームは、最近、スタンドアロンのデスクトップ版スプレッドシート プロセッサから Google Workspace Enterprise エディションに移行しました。財務チームがデータ分析情報を必要なとき、IT チームは BigQuery でクエリを実行してデータを CSV ファイルにエクスポートし、メールの添付ファイルとして財務チームメンバーに送信します。財務チームが慣れているデータ分析方法を変えずにこのプロセスを改善するには、どうすればよいですか。
A. BigQuery でクエリを実行して、分析可能な結果ビューへのアクセスを財務チームに許可します。
B. BigQuery でクエリを実行して、Google データポータルのデータ ビジュアリゼーションへのアクセスを財務チームに許可します。
C. BigQuery でクエリを実行して、データを CSV にエクスポートし、そのファイルを Cloud Storage バケットにアップロードして財務チームと共有します。
D. BigQuery でクエリを実行して、財務チームがアクセスして分析できる Google スプレッドシートの共有スプレッドシートに結果を保存します。

## A. D
Dは以下全てを満たす。
シームレスな統合: BigQueryには、クエリ結果を直接 Google スプレッドシートに出力する機能があります。これにより、ITチームはクエリの実行とデータのエクスポートを自動化できます。
慣れた環境: 財務チームは、いつも使っている Google スプレッドシートを開くだけで、最新のデータにアクセスして分析を始めることができます。新しいツールを覚える必要はありません。
プロセスの改善: データをCSVにエクスポートし、メールに添付して送信するという、エラーが発生しやすく時間のかかる手作業を完全に排除できます。

# Q. あなたのスクーター シェアリング会社は、位置、バッテリー残量、速度など、保有するスクーターに関する情報を収集しています。このデータはリアルタイムで可視化されます。断続的な接続を防ぐため、各スクーターは短い間隔で特定のメッセージを繰り返し送信します。時折、データエラーも見受けられます。メッセージは、Pub/Sub で受信されて BigQuery に保存されます。データに重複がなく、空白フィールドのある異常なデータが拒否されるようにするには、どうすればよいですか。
A. データを BigQuery に保存して、異常なデータと重複データのクエリ削除を実行します。
B. Dataflow を使用して Pub/Sub にサブスクライブし、データを処理して BigQuery に保存します。
C. Kubernetes を使用して、重複データと異常データを削除できるマイクロサービス アプリケーションを作成します。その後に、データを BigQuery に挿入します。
D. マネージド インスタンス グループで Compute Engine に重複データと異常データを削除できるアプリケーションを作成します。その後に、データを BigQuery に挿入します。

## A. B
このシナリオの要件は、Pub/Sub からのストリーミングデータを**処理（重複排除と異常値のフィルタリング）してから BigQuery に書き込むことです。このようなストリーミングETL（Extract, Transform, Load）**のタスクに最も適したGoogle Cloudサービスは Dataflow です。

# Q. あなたの暗号通貨取引会社では、価格を可視化してお客様の取引の意思決定をサポートしています。さまざまな取引がリアルタイムで行われるため、価格データは、処理に Dataflow を使用するデータ パイプラインに提供されます。移動平均を計算するにはどうすればよいですか。
A. Dataflow でホッピング ウィンドウを使用します。
B. Dataflow でセッション ウィンドウを使用します。
C. Dataflow でタンブリング ウィンドウを使用します。
D. Dataflow SQL を使用して、時間でグループ化された平均を計算します。

## A. A
ホッピングウィンドウ（Hopping Window）：固定長のウィンドウが、指定された間隔（スライド）で進んでいきます。ウィンドウの長さよりもスライドの間隔を短く設定することで、ウィンドウが重複します。
例: 「5分間のウィンドウを1分ごとに計算する」設定。これはまさしく移動平均の計算方法です。
10:00〜10:05 の平均
10:01〜10:06 の平均
10:02〜10:07 の平均

セッション ウィンドウ (Session Window)：ユーザーの活動期間など、データの無活動期間が一定時間を超えるまでを一つのウィンドウとします。ウィンドウの長さは可変です。ユーザーのサイト滞在時間内の行動分析など。移動平均の計算には不向きです。
タンブリング ウィンドウ (Tumbling Window)：時間軸を固定長で、重複なく分割します。各データは必ず一つのウィンドウにのみ属します。これは単なる時間毎の集計です。

# Q. あなたは、数百万人のトレーダーがいる証券取引所用の取引プラットフォームを構築しています。取引データは迅速に書き込まれます。あなたは、特定の株式の経時的な価格変動などのデータを迅速に取得して、可視化データをトレーダーに表示する必要があります。そのために Google Cloud のストレージ ソリューションを選択しなくてはなりません。どうすればよいですか。
A. Bigtable を使用します。
B. Firestore を使用します。
C. Cloud SQL を使用します。
D. Memorystore を使用します。

# A. A
下記要件を満たす最も最適な選択肢である。
高い書き込み性能: Bigtableは、毎秒数百万のリクエストを処理できるように設計されており、金融取引のような大量のストリーミングデータをリアルタイムで取り込むのに最適です。
時系列データに最適: 行キーを [株式コード]#[タイムスタンプ] のように設計することで、特定の株式の価格データを時系列順に格納できます。これにより、「特定の株式の経時的な価格変動」を取得するクエリは、非常に高速な連続した行のスキャンとなり、パフォーマンスが最大化されます。
スケーラビリティ: 数百万人のトレーダーと膨大な取引データを扱うための水平スケーラビリティを備えています。

Firestore: ドキュメント指向のNoSQLデータベースで、モバイルアプリやWebアプリのバックエンドに適しています。高頻度の時系列データの取り込みと分析的なスキャンは、Firestoreの主な得意分野ではありません。特に、オペレーションごとの課金モデルは、取引データのような大量の書き込みが発生する場合、コストが非常に高くなる可能性があります。
Cloud SQL: マネージド型のリレーショナルデータベースです。リレーショナルデータベースは、これほど大規模で高スループットな書き込み負荷がかかると、パフォーマンスのボトルネックになりがちです。また、時系列データのクエリも、Bigtableのようなワイドカラムストアほど効率的ではありません。
Memorystore: インメモリのデータストア（Redis/Memcached）です。非常に高速ですが、インメモリであるため、永続的に保存する必要がある大量の取引履歴データをすべて保持するにはコストがかかりすぎます。最新の価格をキャッシュするなど、補助的な役割には適していますが、メインのデータストアとしては不適切です。

# Q. お客様は、Hadoop と Spark を使用してデータ分析をオンプレミスで実行しています。主要データはハードディスクに保存され、アクセスは一元的です。お客様は、スケーラビリティを考慮しつつ、ワークロードを Google Cloud に効率的に移行する必要があります。作業が最小限のアーキテクチャを選択するには、どうすればよいですか。
A. Dataproc を使用して Hadoop と Spark のジョブを実行します。データを Cloud Storage に移動します。
B. Dataflow を使用して、サーバーレス アプローチでジョブを再作成します。データを Cloud Storage に移動します。
C. Dataproc を使用して Hadoop と Spark のジョブを実行します。永続ディスクが接続された Compute Engine VM でデータを保持します。
D. Dataflow を使用して、サーバーレス アプローチでジョブを再作成します。永続ディスクが接続された Compute Engine VM でデータを保持します。

## A. A

# Q. あなたは BigQuery で作業するアナリスト チームのメンバーで、すでに SQL に精通しています。チームは、BigQuery のデータを使用する、マルチラベルの機械学習分類モデルを構築する必要があります。トレーニング データセットには 6,000 行のデータがあります。推論は 200 のラベルの可能性の内の一つとなると考えられます。高精度のモデルを作成するにはどうすればよいですか。
A. BigQuery ML を使用してモデルを作成します。
B. データを CSV ファイルにエクスポートします。TensorFlow を使用してモデルを構築します。
C. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。
D. AI Notebooks を使用してデータに接続して、モデルをインタラクティブに構築します。

## A. C
このシナリオで最も重要な要件は、**高精度のモデルを作成する**ことです。データセットが6,000行と比較的小さいことを考えると、各選択肢は以下のように評価できます。
* **A. BigQuery ML を使用してモデルを作成します。**
    * **利点**: SQLに精通したチームにとって、`CREATE MODEL` 構文を使ってSQL内で直接モデルを構築できるため、最も学習コストが低く、迅速に作業を開始できます。
    * **欠点**: モデルの種類やハイパーパラメータのチューニングに制限があり、必ずしも最高の精度を達成できるとは限りません。

* **B. データを CSV ファイルにエクスポートします。TensorFlow を使用してモデルを構築します。**
    * **利点**: モデルのアーキテクチャを完全に自由に設計できるため、理論的には最高の精度を追求できます。
    * **欠点**: SQLに精通したチームが、PythonとTensorFlowを習得するには多大な時間と労力がかかります。また、6,000行という小さなデータセットに対して複雑なモデルを一から構築すると、**過学習（Overfitting）**を起こしやすく、かえって精度が低下するリスクがあります。

* **C. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。 (正解)** ✅
    * **利点**:
        * **高精度**: **Vertex AI AutoML** は、Googleの最先端の機械学習技術を活用し、データに最適なモデルアーキテクチャとハイパーパラメータを**自動で探索**します。特に、数千から数万行程度の表形式データに対しては、手動で構築したモデルを上回る精度を達成することがよくあります。
        * **使いやすさ**: BigQueryテーブルをデータソースとして直接指定でき、MLの専門知識がなくても高精度のモデルを構築できます。
        * **効率**: モデル開発の試行錯誤にかかる時間を大幅に削減できます。
    * **結論**: 「高精度」という目標を達成する可能性が最も高く、効率的な選択肢です。

* **D. AI Notebooks を使用してデータに接続して、モデルをインタラクティブに構築します。**
    * **利点**: 対話形式でデータ分析やモデル構築を進められるため、実験には便利です。
    * **欠点**: これはモデルを構築する「環境」を指しているだけで、結局はBのようにTensorFlowやScikit-learnといったライブラリを使って自分たちでコードを書く必要があります。Bと同じく、SQLチームにとってはスキル的なハードルが高いです。

# Q. 少量のデータを使用して、テスト時に適切な推論を提示する機械学習モデルを作成しましたが、結果は、実世界データを使用してモデルを実行するとエラーが多くなることを示しています。テストのために追加データを収集することはできません。モデルの能力をもっと正確に把握するにはどうすればよいですか。
A. データ量を減らしてモデルを改善します。
B. データを交差検証して、モデル構築プロセスを再度実行します。
C. 新しい列を追加する特徴クロスを作成して、データ量を増やします。
D. データを 2 回複製してデータを増やし、モデル構築プロセスを再度実行します。

## A. B
このシナリオでは、過学習が起きています。交差検証（Cross-Validation）**は、まさにこのような状況のためにある標準的な評価手法です。
仕組み: データを複数のグループ（例: 5個）に分割し、そのうちの1つをテスト用、残りを訓練用としてモデルを評価します。これを、すべてのグループが1回ずつテスト用になるまで繰り返します。
利点: この方法により、手持ちの限られたデータを最大限に活用し、単一の訓練・テスト分割よりもはるかに信頼性の高い、安定したモデル性能の評価値を得ることができます。これにより、モデルが実世界でどの程度の実力を持つかをより正確に把握できます。
Cの特徴クロスはモデルの表現力を高める手法ですが、データの**行数（サンプル数）**は増えません。サンプルの少ないデータセットで特徴量（列数）を増やすと、モデルがさらに複雑になり、過学習のリスクを高める可能性があります。
Dのデータの単純複製は、モデルに新しい情報を与えることにはなりません。全く同じデータを繰り返し見せるだけなので、過学習を改善する効果はなく、モデルの評価にも役立ちません。

# Q. あなたの組織は、住所やクレジット カード詳細など、お客様に関する情報を多年にわたり収集しており、この顧客データを使用して Google Cloud に機械学習モデルを構築する予定です。あなたは機械学習モデルへの個人データの漏洩を心配しています。経営陣も、個人データの直接的な漏洩により同社の評判が損なわれることを懸念しています。データ セキュリティに関するこのような懸念に対処するには、どうすればよいですか。
A. センシティブ データを含むすべてのテーブルを削除します。
B. SciPy などのライブラリを使用してローカル PC に ML モデルを構築します。
C. Cloud Data Loss Prevention（DLP）API を使用してセンシティブ データを削除します。
D. センシティブ データを含む行を特定し、SQL クエリを使用してこれらの行だけを削除します。

## A. C
Cloud DLP は、まさにこの課題を解決するために設計されたGoogle Cloudのマネージドサービスです。下記の要件を満たすので最適です。
自動検出: クレジットカード番号、住所、氏名などの機密データを自動で検出・分類します。
無害化: 検出したデータをただ削除するだけでなく、マスキング（例: XXX-XXXX-1234）やトークン化（例: 元の値を token_123 のような一意のIDに置き換える）といった手法で無害化できます。
トークン化は特にMLで有用です。データの関連性（どのデータが同じ顧客に属するかなど）を維持したまま、元の機密情報を完全に隠すことができるため、モデルの精度を損なうことなく安全にデータを利用できます。

# Q. あなたの会社のヘルスケアのアプリケーションには、IoT デバイスからイベントデータを直接受け取るバックエンド システムがあります。最近、アプリケーションのユーザーとデバイスが増加しており、システムに負担のかかる突然のデータ流入が発生しています。あなたは、データ パイプラインを再設計して、すべてのデータが処理されイベントが失われないようにする必要があります。Google が推奨する方法に沿って対応する場合、どうすればよいですか。
A. Kafka を pull モードで使用します。
B. Pub/Sub を pull モードで使用します
C. Pub/Sub を push モードで使用します。
D. Cloud Scheduler を一定の間隔で実行します。

## A. B
この問題の核心は、予測不可能なデータ量の急増（バーストトラフィック）に対応し、バックエンドシステムを過負荷から保護しつつ、データ損失を防ぐことです。このような課題に対するGoogle Cloudの標準的なアーキテクチャは、Pub/Sub をメッセージングバッファとして使用することです。
Kafkaも強力なメッセージングシステムですが、Google Cloud上で利用する場合、通常はCompute EngineやKubernetes Engine上で自己管理する必要があり不適切です。
Pub/Subのトピックに送信（Publish）します。Pub/Subは、数百万メッセージ/秒のトラフィックも吸収できるスケーラブルなバッファとして機能します。これにより、バックエンドシステムとデータソースが疎結合になります。
pullモードの利点としては、バックエンドシステム（サブスクライバー）は、自身の処理能力に応じて、準備ができたときにPub/Subからメッセージを能動的に「引き出し（pull）」にいくため、データが急増してもバックエンドは自身のペースで処理を進めることができ、過負荷になることはありません。
Cloud Scheduler は単なる cron であるため不適切。

# Q. レポート生成アプリケーションを毎晩 11:30 PM に実行する Cloud Scheduler のジョブがあります。他のアプリケーションは、レポート情報を Pub/Sub トピックに一日中送信し、レポート生成アプリケーションは同じトピックにサブスクライブされます。すべてのレポート生成リクエストを受信するようにレポート生成アプリケーションを設定するには、どうすればよいですか。
A. pull メカニズムを使用してリクエストされたレポートを収集します。
B. push メカニズムを使用してリクエストされたレポートを収集します。
C. 未処理のメッセージ キューを使用して、リクエストされたレポートを収集します。
D. 毎晩スナップショットを作成して、最後のスナップショット以降に作成されたすべてのレポート リクエストを取得します。

## A. A
pull と push の違い
push メカニズム (B): Pub/Subがメッセージを受信するたびに、即座にサブスクライバー（アプリケーション）にメッセージを送りつけよう（push）とします。しかし、このアプリケーションは夜11:30まで起動していません。そのため、日中に送られてくるメッセージは全て配信に失敗し、最終的には失われてしまいます。
pull メカニズム (A): アプリケーションが自身のタイミングで、Pub/Subにメッセージを取り（pull）にいきます。メッセージは、アプリケーションが取りに来るまでPub/Subのサブスクリプション内に安全に保持されます。夜11:30に起動したアプリケーションは、「まだ処理されていないメッセージをください」とリクエストし、日中に溜まった全てのメッセージを一度に受信して処理することができます。
未処理のメッセージ キュー (Dead-letter queue): これは、メッセージの処理に失敗したときに、そのメッセージを退避させておくための「失敗処理」の仕組みです。通常のメッセージ受信方法ではありません。

# Q. あなたの会社は、オンプレミスのデータセンターを Google Cloud に移動しています。あなたは、MongoDB Atlas をビジネスクリティカルなシステムの一部として実行してきました。今後、マルチクラウド アプローチに移行する予定です。Google Cloud の MongoDB Atlas に最小限の労力で移行するには、どうすればよいですか。
A. Google Cloud Marketplace で、おすすめのバージョンの MongoDB Atlas を選択してインストールします。
B. MongoDB サポートに連絡し、連携して MongoDB Atlas をインストールします。
C. VM を Compute Engine にプロビジョニングし、オンプレミスのデータセンターと同様に MongoDB Atlas をインストールします。
D. オンプレミスの MongoDB を最初に Firestore に移行し、Firestore アプリケーションが安定したら Firestore を MongoDB Atlas に移行します。

## A. A

# Q. あなたは、財務チームが費用請求をもっと迅速に処理できるように支援するツールを構築しています。従業員は、レシートの画像が添付された、説明が最小限の費用請求を提出します。監査と分析のために、レシートの詳細をキャプチャするにはどうすればよいですか。
A. Document AI をワークフローに統合し、レシート画像の情報をキャプチャしてデータベースに追加します。
B. AutoML Vision を使用してレシート画像の情報をキャプチャし、データベースに追加します。
C. Pandas と SciPy を使用してレシート画像から情報を抽出できるモデルを構築して、情報をデータベースに追加します。
D. Cloud Natural Language API を使用してレシート画像からテキストを抽出し、データベースに追加します。

## A. A
Document AI は、まさにこの目的のために設計されたGoogle Cloudのサービスです。請求書やフォーム、そしてレシートのような定型・半定型ドキュメントから、単にテキストを読み取る（OCR）だけでなく、その意味を理解してキーと値のペア（例: {"merchant_name": "ABCマート", "total_amount": "1500"}）として構造化データを抽出します。専用の「Receipt Processor」を利用することで、最小限の開発作業で高精度な情報抽出が可能です。
Natural Language API は、テキストを分析するためのものであり、画像を処理することはできません。まずVision APIなどでOCRを行ってテキストを抽出し、そのテキストをNatural Language APIに渡すことはできますが、それでもレシートの構造（何が合計金額で何が日付か）を理解するのには適していません。

# Q. 機械学習モデルの構築に使用するデータセットがあります。そのデータセットはあなたにはなじみのないものですが、社内の他のユーザーはそれで作業しておりよく知っています。あなたは、ML モデルを反復的に構築しつつ、データを自身で確認したいと考えています。また、インタラクティブに協力してチーム環境で ML モデルを構築することも考えています。  どうすればよいですか。
A. Vertex AI Workbench ノートブックを使用して、ノートブックを同僚と共有します。
B. Google ドキュメントを使用して、ドキュメントを同僚と共有します。
C. BigQuery テーブルを使用して同僚にビューを提供します。
D. BigQuery を使用して、データを Looker で可視化します。ダッシュボードを同僚と共有します。

## A. A
Vertex AI Workbenchは、Google Cloudに最適化されたマネージド型のJupyterノートブック環境です。下記の要件を満たす。
対話的なデータ確認とモデル構築: ノートブック形式なので、コードをセル単位で実行し、その結果（データフレーム、グラフなど）をすぐ下に表示できます。これにより、データを探索しながらモデルを少しずつ構築・改善していく反復的な作業に最適です。
チームでの共同作業: 作成したノートブックファイル（コード、実行結果、メモをすべて含む）は、Gitリポジトリを通じて、または直接ファイルを共有することで、同僚と簡単に共有できます。これにより、チームメンバーは互いの分析や実験の結果を再現・確認しながら共同で作業を進めることができます。

LookerはBI（ビジネスインテリジェンス）ツールであり、データの可視化や分析には非常に強力ですが、MLモデルをコーディングして開発するためのツールではなく不適切。

# Q. あなたの会社は Cloud SQL を 2 つのリージョンで実行しています。1 つ目のリージョンである us-central1 はエンドユーザーに近く、本番環境での使用頻度は多く、予測可能です。もう一つのリージョンである europe-west1 は開発チームに近く、使用は断続的です。労力、レイテンシ、パフォーマンス面で妥協することなく費用を削減するには、どうすればよいですか。
A. 米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当て方法をそのまま保持します
B. 米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当てを米国リージョンに移動し、低い費用のメリットを利用します。
C. 希望する費用の削減の程度に応じて、VM に割り当てられている仮想 CPU の数を 1% 単位で減らします。
D. カスタムのより低コストの VM を Compute Engine にプロビジョニングして、必要に応じてデータベースをインストールします。

## A. A
米国の本番環境は「使用頻度が多く、予測可能」です。このような常に稼働している予測可能なワークロードに対して**確約利用割引（CUD）**を適用するのは、最も効果的で推奨されるコスト削減方法です。1年または3年の利用をコミットすることで、オンデマンド料金から大幅な割引を受けられます。一方、ヨーロッパの開発環境は「断続的」な使用であるため、オンデマンドのままにしておくのが合理的です。この方法は、パフォーマンスや構成を変更することなく、コストだけを削減できます。
